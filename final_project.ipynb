{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO2bP+6AjiR4oU3wc81nby3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Constants"],"metadata":{"id":"cN4DOrVbQj4a"}},{"cell_type":"markdown","source":["[example data](http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/nerf_example_data.zip)"],"metadata":{"id":"FLZe0cmXTlra"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMdA4tixUHV1","executionInfo":{"status":"ok","timestamp":1732644605388,"user_tz":480,"elapsed":2613,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}},"outputId":"844039af-924e-4ec4-e20e-d08c0ff63ce5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/cs117/final project/nerf_pytorch')"],"metadata":{"id":"5BpncRLfenH-","executionInfo":{"status":"ok","timestamp":1732644608403,"user_tz":480,"elapsed":161,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## 1.1 Imports\n"],"metadata":{"id":"bktvA4Aqef2f"}},{"cell_type":"code","source":["from run_nerf import train, generate_video, generate_stills\n","import argparse"],"metadata":{"id":"mx8-RZ3vfDyq","executionInfo":{"status":"ok","timestamp":1732644617272,"user_tz":480,"elapsed":8141,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"HJJs-YLCkPGx"}},{"cell_type":"markdown","source":["# 2. Train"],"metadata":{"id":"2kfylL7Ber1D"}},{"cell_type":"code","source":["args = argparse.Namespace(\n","        N_importance=128,   # Default: 0, Number of additional fine samples per ray\n","        N_rand=1024,        # Default: 32*32*4, Batch size (number of random rays per gradient step)\n","        N_samples=64,       # Default: 64, Number of coarse samples per ray\n","        N_iters=1000,       # Default: 200000, Number of iterations (training steps)\n","        basedir='/content/drive/My Drive/cs117/final project/nerf_pytorch/logs',  # Default: './logs/', Where to store ckpts and logs\n","        chunk=32768,        # Default: 1024*32, Number of rays processed in parallel, decrease if running out of memory\n","        config='/content/drive/My Drive/cs117/final project/nerf_pytorch/configs/lego.txt',  # Default: None, Config file path\n","        datadir='/content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego',  # Default: './data/llff/fern', Input data directory\n","        dataset_type='blender',  # Default: 'llff', Dataset type (options: llff / blender / deepvoxels)\n","        expname='blender_paper_lego',  # Default: None, Experiment name\n","        factor=8,           # Default: 8, Downsample factor for LLFF images\n","        ft_path=None,       # Default: None, Specific weights npy file to reload for coarse network\n","        half_res=False,     # Default: False, Load blender synthetic data at 400x400 instead of 800x800\n","        i_embed=0,          # Default: 0, Set 0 for default positional encoding, -1 for none\n","        i_img=2000,         # Default: 500, Frequency of tensorboard image logging\n","        i_print=100,        # Default: 100, Frequency of console printout and metric logging\n","        i_testset=2000,     # Default: 50000, Frequency of testset saving\n","        i_video=999,        # Default: 50000, Frequency of render_poses video saving\n","        i_weights=2000,     # Default: 10000, Frequency of weight ckpt saving\n","        lindisp=False,      # Default: False, Sampling linearly in disparity rather than depth\n","        llffhold=8,         # Default: 8, Will take every 1/N images as LLFF test set\n","        lrate=0.0005,       # Default: 5e-4, Learning rate\n","        lrate_decay=500,    # Default: 250, Exponential learning rate decay (in 1000 steps)\n","        multires=10,        # Default: 10, Log2 of max freq for positional encoding (3D location)\n","        multires_views=4,   # Default: 4, Log2 of max freq for positional encoding (2D direction)\n","        netchunk=65536,     # Default: 1024*64, Number of points sent through network in parallel\n","        netdepth=8,         # Default: 8, Layers in network\n","        netdepth_fine=8,    # Default: 8, Layers in fine network\n","        netwidth=256,       # Default: 256, Channels per layer\n","        netwidth_fine=256,  # Default: 256, Channels per layer in fine network\n","        no_batching=True,   # Default: False, Only take random rays from 1 image at a time\n","        no_ndc=False,       # Default: False, Do not use normalized device coordinates (set for non-forward facing scenes)\n","        no_reload=False,    # Default: False, Do not reload weights from saved checkpoint\n","        perturb=1.0,        # Default: 1.0, Set to 0. for no jitter, 1. for jitter\n","        precrop_frac=0.5,   # Default: 0.5, Fraction of image taken for central crops\n","        precrop_iters=500,  # Default: 0, Number of steps to train on central crops\n","        raw_noise_std=0.0,  # Default: 0.0, Std dev of noise added to regularize sigma_a output\n","        render_factor=0,    # Default: 0, Downsampling factor to speed up rendering\n","        render_only=False,  # Default: False, Do not optimize, reload weights and render out render_poses path\n","        render_test=False,  # Default: False, Render the test set instead of render_poses path\n","        shape='greek',      # Default: 'greek', Shape for deepvoxels (options: armchair / cube / greek / vase)\n","        spherify=False,     # Default: False, Set for spherical 360 scenes\n","        testskip=8,         # Default: 8, Will load 1/N images from test/val sets, useful for large datasets like deepvoxels\n","        use_viewdirs=True,  # Default: True, Use full 5D input instead of 3D\n","        white_bkgd=True     # Default: False, Set to render synthetic data on a white background (always use for dvoxels)\n","    )\n"],"metadata":{"id":"pm3V9YjkedHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"75JCrE1AeznP","outputId":"4799a4b0-919b-49c8-a31e-e359830fa7f6","executionInfo":{"status":"error","timestamp":1732642540798,"user_tz":480,"elapsed":201,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}}},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'args' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-aad596905035>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"]}]},{"cell_type":"code","source":["args = argparse.Namespace(\n","        N_importance=128,   # Default: 0, Number of additional fine samples per ray\n","        N_rand=1024,        # Default: 32*32*4, Batch size (number of random rays per gradient step)\n","        N_samples=64,       # Default: 64, Number of coarse samples per ray\n","        N_iters=1000,       # Default: 200000, Number of iterations (training steps)\n","        basedir='/content/drive/My Drive/cs117/final project/nerf_pytorch/logs',  # Default: './logs/', Where to store ckpts and logs\n","        chunk=32768,        # Defauloogle.com/document/d/1UT_bFO7Lz_9m0GOfCJuXF2p-h9hn0PMbMm7z3ohP4ZI/edit?usp=sharingt: 1024*32, Number of rays processed in parallel, decrease if running out of memory\n","        config='/content/drive/My Drive/cs117/final project/nerf_pytorch/configs/lego.txt',  # Default: None, Config file path\n","        datadir='/content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego',  # Default: './data/llff/fern', Input data directory\n","        dataset_type='blender',  # Default: 'llff', Dataset type (options: llff / blender / deepvoxels)\n","        expname='blender_paper_lego',  # Default: None, Experiment name\n","        factor=8,           # Default: 8, Downsample factor for LLFF images\n","        ft_path= '/content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar',       # Default: None, Specific weights npy file to reload for coarse network\n","        half_res=False,     # Default: False, Load blender synthetic data at 400x400 instead of 800x800\n","        i_embed=0,          # Default: 0, Set 0 for default positional encoding, -1 for none\n","        i_img=2000,         # Default: 500, Frequency of tensorboard image logging\n","        i_print=100,        # Default: 100, Frequency of console printout and metric logging\n","        i_testset=2000,     # Default: 50000, Frequency of testset saving\n","        i_video=999,        # Default: 50000, Frequency of render_poses video saving\n","        i_weights=2000,     # Default: 10000, Frequency of weight ckpt saving\n","        lindisp=False,      # Default: False, Sampling linearly in disparity rather than depth\n","        llffhold=8,         # Default: 8, Will take every 1/N images as LLFF test set\n","        lrate=0.0005,       # Default: 5e-4, Learning rate\n","        lrate_decay=500,    # Default: 250, Exponential learning rate decay (in 1000 steps)\n","        multires=10,        # Default: 10, Log2 of max freq for positional encoding (3D location)\n","        multires_views=4,   # Default: 4, Log2 of max freq for positional encoding (2D direction)\n","        netchunk=65536,     # Default: 1024*64, Number of points sent through network in parallel\n","        netdepth=8,         # Default: 8, Layers in network\n","        netdepth_fine=8,    # Default: 8, Layers in fine network\n","        netwidth=256,       # Default: 256, Channels per layer\n","        netwidth_fine=256,  # Default: 256, Channels per layer in fine network\n","        no_batching=True,   # Default: False, Only take random rays from 1 image at a time\n","        no_ndc=False,       # Default: False, Do not use normalized device coordinates (set for non-forward facing scenes)\n","        no_reload=False,    # Default: False, Do not reload weights from saved checkpoint\n","        perturb=1.0,        # Default: 1.0, Set to 0. for no jitter, 1. for jitter\n","        precrop_frac=0.5,   # Default: 0.5, Fraction of image taken for central crops\n","        precrop_iters=500,  # Default: 0, Number of steps to train on central crops\n","        raw_noise_std=0.0,  # Default: 0.0, Std dev of noise added to regularize sigma_a output\n","        render_factor=0,    # Default: 0, Downsampling factor to speed up rendering\n","        render_only=False,  # Default: False, Do not optimize, reload weights and render out render_poses path\n","        render_test=False,  # Default: False, Render the test set instead of render_poses path\n","        shape='greek',      # Default: 'greek', Shape for deepvoxels (options: armchair / cube / greek / vase)\n","        spherify=False,     # Default: False, Set for spherical 360 scenes\n","        testskip=8,         # Default: 8, Will load 1/N images from test/val sets, useful for large datasets like deepvoxels\n","        use_viewdirs=True,  # Default: True, Use full 5D input instead of 3D\n","        white_bkgd=True     # Default: False, Set to render synthetic data on a white background (always use for dvoxels)\n","    )\n"],"metadata":{"id":"hmfDKhCO2spk","executionInfo":{"status":"ok","timestamp":1732644623971,"user_tz":480,"elapsed":159,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["generate_video(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1O8tjROb5ITm","executionInfo":{"status":"ok","timestamp":1732642841353,"user_tz":480,"elapsed":292621,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}},"outputId":"63d7d37c-8581-496b-b150-f756172e6806"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n"]},{"output_type":"stream","name":"stdout","text":["Found ckpts ['/content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar']\n","Reloading from /content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar\n","Not ndc!\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf.py:225: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(ckpt_path)\n"]},{"output_type":"stream","name":"stdout","text":["Loaded blender (138, 800, 800, 4) torch.Size([3, 4, 4]) [800, 800, 1111.1110311937682] /content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["0 0.0046727657318115234\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 1/3 [01:34<03:09, 94.52s/it]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([800, 800, 3]) torch.Size([800, 800])\n","1 94.51798510551453\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 2/3 [03:08<01:34, 94.21s/it]"]},{"output_type":"stream","name":"stdout","text":["2 93.98911309242249\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3/3 [04:42<00:00, 94.29s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Done, saving (3, 800, 800, 3) (3, 800, 800)\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf_helpers.py:11: RuntimeWarning: invalid value encountered in cast\n","  to8b = lambda x : (255*np.clip(x,0,1)).astype(np.uint8)\n"]}]},{"cell_type":"code","source":["generate_stills(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"R8Ih4MDOpRy3","executionInfo":{"status":"error","timestamp":1732644627373,"user_tz":480,"elapsed":566,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}},"outputId":"752fc83d-60a7-4576-caa9-38af566f919d"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-b400e632e448>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_stills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf.py\u001b[0m in \u001b[0;36mgenerate_stills\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_tensor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torch.cuda.FloatTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0mrender_kwargs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_kwargs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_nerf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m     \u001b[0;31m#----------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhwf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_blender_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf.py\u001b[0m in \u001b[0;36mcreate_nerf\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \"\"\"Instantiate NeRF's MLP model.\n\u001b[1;32m    180\u001b[0m     \"\"\"\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0membed_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultires\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0minput_ch_views\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf_helpers.py\u001b[0m in \u001b[0;36mget_embedder\u001b[0;34m(multires, i)\u001b[0m\n\u001b[1;32m     59\u001b[0m     }\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0membedder_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0membed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0membed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedder_obj\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0meo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_embedding_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_embedding_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf_helpers.py\u001b[0m in \u001b[0;36mcreate_embedding_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_sampling'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mfreq_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_freqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mfreq_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmax_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_freqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}]}]}