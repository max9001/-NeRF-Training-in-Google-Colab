{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNVRbXKRk5JjVwNUlz8Wlv9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1. Constants"],"metadata":{"id":"cN4DOrVbQj4a"}},{"cell_type":"markdown","source":["[example data](http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/nerf_example_data.zip)"],"metadata":{"id":"FLZe0cmXTlra"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMdA4tixUHV1","executionInfo":{"status":"ok","timestamp":1732641090452,"user_tz":480,"elapsed":19466,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}},"outputId":"afdace03-9eb9-49d4-eaed-a539b2883f25"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/My Drive/cs117/final project/nerf_pytorch')"],"metadata":{"id":"5BpncRLfenH-","executionInfo":{"status":"ok","timestamp":1732641092266,"user_tz":480,"elapsed":216,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## 1.1 Imports\n"],"metadata":{"id":"bktvA4Aqef2f"}},{"cell_type":"code","source":["from run_nerf import train, generate_video\n","import argparse"],"metadata":{"id":"mx8-RZ3vfDyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"HJJs-YLCkPGx"}},{"cell_type":"markdown","source":["# 2. Train"],"metadata":{"id":"2kfylL7Ber1D"}},{"cell_type":"code","source":["args = argparse.Namespace(\n","        N_importance=128,   # Default: 0, Number of additional fine samples per ray\n","        N_rand=1024,        # Default: 32*32*4, Batch size (number of random rays per gradient step)\n","        N_samples=64,       # Default: 64, Number of coarse samples per ray\n","        N_iters=1000,       # Default: 200000, Number of iterations (training steps)\n","        basedir='/content/drive/My Drive/cs117/final project/nerf_pytorch/logs',  # Default: './logs/', Where to store ckpts and logs\n","        chunk=32768,        # Default: 1024*32, Number of rays processed in parallel, decrease if running out of memory\n","        config='/content/drive/My Drive/cs117/final project/nerf_pytorch/configs/lego.txt',  # Default: None, Config file path\n","        datadir='/content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego',  # Default: './data/llff/fern', Input data directory\n","        dataset_type='blender',  # Default: 'llff', Dataset type (options: llff / blender / deepvoxels)\n","        expname='blender_paper_lego',  # Default: None, Experiment name\n","        factor=8,           # Default: 8, Downsample factor for LLFF images\n","        ft_path=None,       # Default: None, Specific weights npy file to reload for coarse network\n","        half_res=False,     # Default: False, Load blender synthetic data at 400x400 instead of 800x800\n","        i_embed=0,          # Default: 0, Set 0 for default positional encoding, -1 for none\n","        i_img=2000,         # Default: 500, Frequency of tensorboard image logging\n","        i_print=100,        # Default: 100, Frequency of console printout and metric logging\n","        i_testset=2000,     # Default: 50000, Frequency of testset saving\n","        i_video=999,        # Default: 50000, Frequency of render_poses video saving\n","        i_weights=2000,     # Default: 10000, Frequency of weight ckpt saving\n","        lindisp=False,      # Default: False, Sampling linearly in disparity rather than depth\n","        llffhold=8,         # Default: 8, Will take every 1/N images as LLFF test set\n","        lrate=0.0005,       # Default: 5e-4, Learning rate\n","        lrate_decay=500,    # Default: 250, Exponential learning rate decay (in 1000 steps)\n","        multires=10,        # Default: 10, Log2 of max freq for positional encoding (3D location)\n","        multires_views=4,   # Default: 4, Log2 of max freq for positional encoding (2D direction)\n","        netchunk=65536,     # Default: 1024*64, Number of points sent through network in parallel\n","        netdepth=8,         # Default: 8, Layers in network\n","        netdepth_fine=8,    # Default: 8, Layers in fine network\n","        netwidth=256,       # Default: 256, Channels per layer\n","        netwidth_fine=256,  # Default: 256, Channels per layer in fine network\n","        no_batching=True,   # Default: False, Only take random rays from 1 image at a time\n","        no_ndc=False,       # Default: False, Do not use normalized device coordinates (set for non-forward facing scenes)\n","        no_reload=False,    # Default: False, Do not reload weights from saved checkpoint\n","        perturb=1.0,        # Default: 1.0, Set to 0. for no jitter, 1. for jitter\n","        precrop_frac=0.5,   # Default: 0.5, Fraction of image taken for central crops\n","        precrop_iters=500,  # Default: 0, Number of steps to train on central crops\n","        raw_noise_std=0.0,  # Default: 0.0, Std dev of noise added to regularize sigma_a output\n","        render_factor=0,    # Default: 0, Downsampling factor to speed up rendering\n","        render_only=False,  # Default: False, Do not optimize, reload weights and render out render_poses path\n","        render_test=False,  # Default: False, Render the test set instead of render_poses path\n","        shape='greek',      # Default: 'greek', Shape for deepvoxels (options: armchair / cube / greek / vase)\n","        spherify=False,     # Default: False, Set for spherical 360 scenes\n","        testskip=8,         # Default: 8, Will load 1/N images from test/val sets, useful for large datasets like deepvoxels\n","        use_viewdirs=True,  # Default: True, Use full 5D input instead of 3D\n","        white_bkgd=True     # Default: False, Set to render synthetic data on a white background (always use for dvoxels)\n","    )\n"],"metadata":{"id":"pm3V9YjkedHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75JCrE1AeznP","outputId":"9d0f887a-49a1-4c14-a035-3743efdfd8c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n"]},{"output_type":"stream","name":"stdout","text":["Loaded blender (138, 800, 800, 4) torch.Size([100, 4, 4]) [800, 800, 1111.1110311937682] /content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego\n","Found ckpts []\n","Not ndc!\n","Begin\n","TRAIN views are [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n"," 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n"," 96 97 98 99]\n","TEST views are [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130\n"," 131 132 133 134 135 136 137]\n","VAL views are [100 101 102 103 104 105 106 107 108 109 110 111 112]\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1000 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["[Config] Center cropping of size 400 x 400 is enabled until iter 500\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"," 10%|█         | 100/1000 [00:32<04:50,  3.10it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 100 Loss: 0.20691648125648499  PSNR: 9.805758476257324\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 200/1000 [01:05<04:25,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 200 Loss: 0.16513992846012115  PSNR: 10.762726783752441\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 300/1000 [01:38<03:54,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 300 Loss: 0.1332927644252777  PSNR: 11.99068546295166\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 400/1000 [02:11<03:21,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 400 Loss: 0.06835528463125229  PSNR: 14.951720237731934\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 500/1000 [02:44<02:46,  3.01it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 500 Loss: 0.0546555332839489  PSNR: 15.83114242553711\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 600/1000 [03:18<02:16,  2.93it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 600 Loss: 0.022547515109181404  PSNR: 19.684213638305664\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 700/1000 [03:52<01:40,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 700 Loss: 0.026590434834361076  PSNR: 19.07723045349121\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 800/1000 [04:25<01:07,  2.98it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 800 Loss: 0.018093228340148926  PSNR: 20.63665008544922\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 900/1000 [04:59<00:34,  2.92it/s]"]},{"output_type":"stream","name":"stdout","text":["[TRAIN] Iter: 900 Loss: 0.024566106498241425  PSNR: 19.458417892456055\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 998/1000 [05:32<00:00,  3.02it/s]\n","  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["0 0.007711172103881836\n"]},{"output_type":"stream","name":"stderr","text":["\n","  1%|          | 1/100 [01:32<2:32:33, 92.46s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["torch.Size([800, 800, 3]) torch.Size([800, 800])\n","1 92.4638123512268\n"]},{"output_type":"stream","name":"stderr","text":["\n","  2%|▏         | 2/100 [03:04<2:30:52, 92.38s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["2 92.3207106590271\n"]},{"output_type":"stream","name":"stderr","text":["\n","  3%|▎         | 3/100 [04:37<2:29:18, 92.36s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["3 92.335134267807\n"]},{"output_type":"stream","name":"stderr","text":["\n","  4%|▍         | 4/100 [06:09<2:27:48, 92.38s/it]\u001b[A"]},{"output_type":"stream","name":"stdout","text":["4 92.4022045135498\n"]}]},{"cell_type":"code","source":["args = argparse.Namespace(\n","        N_importance=128,   # Default: 0, Number of additional fine samples per ray\n","        N_rand=1024,        # Default: 32*32*4, Batch size (number of random rays per gradient step)\n","        N_samples=64,       # Default: 64, Number of coarse samples per ray\n","        N_iters=1000,       # Default: 200000, Number of iterations (training steps)\n","        basedir='/content/drive/My Drive/cs117/final project/nerf_pytorch/logs',  # Default: './logs/', Where to store ckpts and logs\n","        chunk=32768,        # Defauloogle.com/document/d/1UT_bFO7Lz_9m0GOfCJuXF2p-h9hn0PMbMm7z3ohP4ZI/edit?usp=sharingt: 1024*32, Number of rays processed in parallel, decrease if running out of memory\n","        config='/content/drive/My Drive/cs117/final project/nerf_pytorch/configs/lego.txt',  # Default: None, Config file path\n","        datadir='/content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego',  # Default: './data/llff/fern', Input data directory\n","        dataset_type='blender',  # Default: 'llff', Dataset type (options: llff / blender / deepvoxels)\n","        expname='blender_paper_lego',  # Default: None, Experiment name\n","        factor=8,           # Default: 8, Downsample factor for LLFF images\n","        ft_path= '/content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar',       # Default: None, Specific weights npy file to reload for coarse network\n","        half_res=False,     # Default: False, Load blender synthetic data at 400x400 instead of 800x800\n","        i_embed=0,          # Default: 0, Set 0 for default positional encoding, -1 for none\n","        i_img=2000,         # Default: 500, Frequency of tensorboard image logging\n","        i_print=100,        # Default: 100, Frequency of console printout and metric logging\n","        i_testset=2000,     # Default: 50000, Frequency of testset saving\n","        i_video=999,        # Default: 50000, Frequency of render_poses video saving\n","        i_weights=2000,     # Default: 10000, Frequency of weight ckpt saving\n","        lindisp=False,      # Default: False, Sampling linearly in disparity rather than depth\n","        llffhold=8,         # Default: 8, Will take every 1/N images as LLFF test set\n","        lrate=0.0005,       # Default: 5e-4, Learning rate\n","        lrate_decay=500,    # Default: 250, Exponential learning rate decay (in 1000 steps)\n","        multires=10,        # Default: 10, Log2 of max freq for positional encoding (3D location)\n","        multires_views=4,   # Default: 4, Log2 of max freq for positional encoding (2D direction)\n","        netchunk=65536,     # Default: 1024*64, Number of points sent through network in parallel\n","        netdepth=8,         # Default: 8, Layers in network\n","        netdepth_fine=8,    # Default: 8, Layers in fine network\n","        netwidth=256,       # Default: 256, Channels per layer\n","        netwidth_fine=256,  # Default: 256, Channels per layer in fine network\n","        no_batching=True,   # Default: False, Only take random rays from 1 image at a time\n","        no_ndc=False,       # Default: False, Do not use normalized device coordinates (set for non-forward facing scenes)\n","        no_reload=False,    # Default: False, Do not reload weights from saved checkpoint\n","        perturb=1.0,        # Default: 1.0, Set to 0. for no jitter, 1. for jitter\n","        precrop_frac=0.5,   # Default: 0.5, Fraction of image taken for central crops\n","        precrop_iters=500,  # Default: 0, Number of steps to train on central crops\n","        raw_noise_std=0.0,  # Default: 0.0, Std dev of noise added to regularize sigma_a output\n","        render_factor=0,    # Default: 0, Downsampling factor to speed up rendering\n","        render_only=False,  # Default: False, Do not optimize, reload weights and render out render_poses path\n","        render_test=False,  # Default: False, Render the test set instead of render_poses path\n","        shape='greek',      # Default: 'greek', Shape for deepvoxels (options: armchair / cube / greek / vase)\n","        spherify=False,     # Default: False, Set for spherical 360 scenes\n","        testskip=8,         # Default: 8, Will load 1/N images from test/val sets, useful for large datasets like deepvoxels\n","        use_viewdirs=True,  # Default: True, Use full 5D input instead of 3D\n","        white_bkgd=True     # Default: False, Set to render synthetic data on a white background (always use for dvoxels)\n","    )\n"],"metadata":{"id":"hmfDKhCO2spk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generate_video(args)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":855},"id":"1O8tjROb5ITm","executionInfo":{"status":"error","timestamp":1732577627669,"user_tz":480,"elapsed":2026132,"user":{"displayName":"Max Rehm","userId":"06043345428080776192"}},"outputId":"79e63488-fb3e-454c-e8bf-9bb901139471"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n","  _C._set_default_tensor_type(t)\n"]},{"output_type":"stream","name":"stdout","text":["Found ckpts ['/content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar']\n","Reloading from /content/drive/My Drive/cs117/final project/nerf_pytorch/logs/blender_paper_lego/010000.tar\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf.py:225: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  ckpt = torch.load(ckpt_path)\n"]},{"output_type":"stream","name":"stdout","text":["Not ndc!\n","Loaded blender (138, 800, 800, 4) torch.Size([20, 4, 4]) [800, 800, 1111.1110311937682] /content/drive/My Drive/cs117/final project/nerf_pytorch/data/nerf_synthetic/lego\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["0 0.00795292854309082\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 1/20 [01:36<30:35, 96.62s/it]"]},{"output_type":"stream","name":"stdout","text":["torch.Size([800, 800, 3]) torch.Size([800, 800])\n","1 96.61554050445557\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 2/20 [03:14<29:16, 97.59s/it]"]},{"output_type":"stream","name":"stdout","text":["2 98.26679611206055\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 3/20 [04:53<27:49, 98.22s/it]"]},{"output_type":"stream","name":"stdout","text":["3 98.97262358665466\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 4/20 [06:32<26:14, 98.38s/it]"]},{"output_type":"stream","name":"stdout","text":["4 98.62206959724426\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 5/20 [08:11<24:39, 98.64s/it]"]},{"output_type":"stream","name":"stdout","text":["5 99.10792946815491\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 6/20 [09:50<23:01, 98.68s/it]"]},{"output_type":"stream","name":"stdout","text":["6 98.76032090187073\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 7/20 [11:28<21:21, 98.59s/it]"]},{"output_type":"stream","name":"stdout","text":["7 98.40914011001587\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 8/20 [13:07<19:44, 98.67s/it]"]},{"output_type":"stream","name":"stdout","text":["8 98.8239517211914\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 9/20 [14:46<18:05, 98.66s/it]"]},{"output_type":"stream","name":"stdout","text":["9 98.653244972229\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 10/20 [16:25<16:27, 98.73s/it]"]},{"output_type":"stream","name":"stdout","text":["10 98.88490653038025\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 11/20 [18:03<14:48, 98.69s/it]"]},{"output_type":"stream","name":"stdout","text":["11 98.60411810874939\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 12/20 [19:42<13:09, 98.71s/it]"]},{"output_type":"stream","name":"stdout","text":["12 98.74288988113403\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 13/20 [21:21<11:31, 98.83s/it]"]},{"output_type":"stream","name":"stdout","text":["13 99.0938708782196\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 14/20 [23:00<09:52, 98.79s/it]"]},{"output_type":"stream","name":"stdout","text":["14 98.71165752410889\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 15/20 [24:38<08:13, 98.75s/it]"]},{"output_type":"stream","name":"stdout","text":["15 98.653240442276\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 16/20 [26:17<06:35, 98.81s/it]"]},{"output_type":"stream","name":"stdout","text":["16 98.9630184173584\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 17/20 [27:56<04:56, 98.81s/it]"]},{"output_type":"stream","name":"stdout","text":["17 98.7989890575409\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 18/20 [29:35<03:17, 98.79s/it]"]},{"output_type":"stream","name":"stdout","text":["18 98.74486517906189\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 19/20 [31:14<01:38, 98.81s/it]"]},{"output_type":"stream","name":"stdout","text":["19 98.85043668746948\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 20/20 [32:53<00:00, 98.66s/it]"]},{"output_type":"stream","name":"stdout","text":["Done, saving (20, 800, 800, 3) (20, 800, 800)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'basedir' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e648d9272b4d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/My Drive/cs117/final project/nerf_pytorch/run_nerf.py\u001b[0m in \u001b[0;36mgenerate_video\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mrgbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_poses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhwf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_kwargs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done, saving'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m     \u001b[0mmoviebase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{}_spiral_{:06d}_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoviebase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'rgb.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto8b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoviebase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'disp.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto8b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'basedir' is not defined"]}]}]}